{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from azure.identity import DefaultAzureCredential \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HTTPStatus.BAD_REQUEST: 400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import exc\n",
    "import importlib\n",
    "importlib.reload(exc)\n",
    "exc.OpenAIMaxTokenExc('test').to_json()\n",
    "exc.OpenAIMaxTokenExc('test').status_code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import UsedQuota, calculate_wait_time\n",
    "from datetime import datetime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_quotas = []\n",
    "# 全体を10Kとして、7Kがすでに使用済みとして計算してみる。\n",
    "available = 3\n",
    "used_quotas.append(UsedQuota(model_identity='test', tokens=3, timestamp=datetime(year=2024, month=10, day=10, hour=0, minute=0, second=50)))\n",
    "used_quotas.append(UsedQuota(model_identity='test', tokens=4, timestamp=datetime(year=2024, month=10, day=10, hour=0, minute=1, second=5)))\n",
    "now_timestamp = datetime(year=2024, month=10, day=10, hour=0, minute=1, second=30)\n",
    "calculate_wait_time(used_quotas=used_quotas, request_tokens=10, now_available_quota=available, now_timestamp=now_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'text-embedding-ada-002', 'tokens': 1655, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 2692, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 1213, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 2366, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 1272, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 3284, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 2159, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 4206, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 1692, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 1443, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 4931, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 3975, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 3663, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 2212, 'wait_seconds': 48}\n",
      "{'model_name': 'text-embedding-ada-002', 'tokens': 4016, 'wait_seconds': 48}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from multiprocessing import Pool\n",
    "from src.openai.cfg import ModelNameEnum\n",
    "import random \n",
    "import time \n",
    "url = 'http://localhost:8000/request_quota' \n",
    "\n",
    "def request_token(args: dict) -> dict:\n",
    "    model: ModelNameEnum = args['model']\n",
    "    tokens: int = args['tokens']\n",
    "    comp_url = url + f'?model_name={model.value}&tokens={tokens}'\n",
    "    response = requests.get(comp_url)\n",
    "    return response.json()\n",
    "\n",
    "def gen_tokens():\n",
    "    return random.randint(1000, 5000)\n",
    "\n",
    "model = ModelNameEnum.embedding_ada_002 \n",
    "for _ in range(15):\n",
    "    res = request_token({'model': model, 'tokens': gen_tokens()})\n",
    "    print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'text-embedding-3-large', 'tokens': 8191, 'wait_seconds': 17}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
